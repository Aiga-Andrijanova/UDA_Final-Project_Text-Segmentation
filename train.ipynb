{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiga/miniconda3/envs/uda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-04 20:16:51.318287: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-04 20:16:51.319749: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-04 20:16:51.338223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-04 20:16:51.338235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-04 20:16:51.338969: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-04 20:16:51.342419: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 20:16:51.750120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(30224) # No randomness in my code is introduced by numpy, so this doesn't matter\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from seg_helpers import run_prediction\n",
    "from dataset import *\n",
    "from pathlib import Path\n",
    "from model import Unet3Plus, DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "parser.add_argument('-checkpoint_path', \n",
    "                    default=\"./results/Unet3+_restart_2024-01-02_16-15-36/image_model_best_iou-0.761.pth\", type=str,\n",
    "                    help=\"Path to .pth file where model weights are saved\")\n",
    "parser.add_argument('-project_dir', default=\"./results\", type=str,\n",
    "                    help=\"Path to directory where to save run results\")\n",
    "parser.add_argument('-run_name', \n",
    "                    default='Unet3+_TEST_RUN', type=str,\n",
    "                    help=\"Run name\")\n",
    "\n",
    "# Training parameters\n",
    "parser.add_argument('-epoch_count', default=10, type=int)\n",
    "parser.add_argument('-learning_rate', default=1e-5, type=float)\n",
    "parser.add_argument('-batch_size', default=4, type=int)\n",
    "parser.add_argument('-checkpoint_interval', default=1, type=int,\n",
    "                    help=\"Interval after how many epochs save model state\")\n",
    "parser.add_argument('-run_inference', default=True, type=bool)\n",
    "parser.add_argument('-inference_interval', default=5, type=int,\n",
    "                    help=\"If run_inference set to true, interval after how many epochs perform inference\")\n",
    "parser.add_argument('-imgs_to_save', default=4, type=int,\n",
    "                    help=\"How many images save in tensorboard per train and evaluation sets\")\n",
    "\n",
    "# Data params\n",
    "parser.add_argument('-data_paths', default=[\"./data/example_data_tiled\"],\n",
    "                                            help=\"A list to root folders of the generated and tiled samples\")\n",
    "parser.add_argument('-test_data_path', default=\"./data/test_data/photos\", type=str,\n",
    "                    help=\"A list to a folder containing test data (.png, .jpg, .jpeg or .pdf files)\")\n",
    "parser.add_argument('-percentage_of_data_to_use', default=1.0, type=float,\n",
    "                    help=\"How much of the samples to use, debug argument\")\n",
    "parser.add_argument('-train_split_size', default=0.9, type=float,\n",
    "                    help=\"How much of the documents put in the train set\")\n",
    "parser.add_argument('-num_workers', default=2 , type=int,\n",
    "                    help=\"How many dataloader workers spawn, if set to 0, none will spawn\")\n",
    "parser.add_argument('-batch_prefetch_factor', default=2, type=int,\n",
    "                    help=\"Batch prefetch fatctor for the dataloader\")\n",
    "parser.add_argument('-input_shape', default=[512, 512, 3], nargs='+', type=int)\n",
    "\n",
    "args, other_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename):\n",
    "    \"\"\"\n",
    "    Load model and optimizer state from a checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to load the weights to.\n",
    "        optimizer: A PyTorch optimizer to load the state to.\n",
    "        filename: The path to the checkpoint file to load.\n",
    "    \n",
    "    Returns:\n",
    "        model: The model with loaded weights.\n",
    "        optimizer: The optimizer with loaded state.\n",
    "        start_epoch: The epoch to start training from.\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            checkpoint = torch.load(filename)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"📂 Loaded checkpoint '{}' (epoch {}) \\n\"\n",
    "                    .format(filename, checkpoint['epoch']))\n",
    "        except KeyError:\n",
    "            checkpoint = torch.load(filename)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(\"📂 Loaded checkpoint '{}' without optimizer and start epoch \\n\"\n",
    "                    .format(filename))\n",
    "    else:\n",
    "        print(\"🚧 No checkpoint found at '{}'\\n\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "def save_model(checkpoint_dir, model, optimizer, epoch, checkpoint_name):\n",
    "    \"\"\"\n",
    "    Save model and optimizer state to a checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_dir: The directory to save the checkpoint to.\n",
    "        model: A PyTorch model to save the weights from.\n",
    "        optimizer: A PyTorch optimizer to save the state from.\n",
    "        epoch: The current epoch to save.\n",
    "        checkpoint_name: The name to save the checkpoint under.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    checkpoint_path = checkpoint_dir/f\"{checkpoint_name}.pth\"\n",
    "    state = {'epoch': epoch + 1, \n",
    "             'model_state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_dataloader, val_dataloader, optimizer,device, start_epoch, epochs, checkpoint_dir, tensorboard_writer):\n",
    "    \"\"\"\n",
    "    Main training loop.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to train.\n",
    "        train_dataloader: A PyTorch DataLoader providing the training data.\n",
    "        val_dataloader: A PyTorch DataLoader providing the validation data.\n",
    "        optimizer: The optimizer to use for training the model.\n",
    "        device: The device (cpu or cuda) to run the model on.\n",
    "        start_epoch: The epoch training starts from\n",
    "        epochs: The number of epochs to train for.\n",
    "        checkpoint_dir: The dir where to save the best model checkpoints and tensorbaord files.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    dice_loss = DiceLoss()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    jaccard = JaccardIndex(task=\"binary\", num_classes=1)\n",
    "\n",
    "    best_iou = 0\n",
    "    for epoch in tqdm(range(start_epoch, epochs, 1), desc=\"Epochs\"):\n",
    "        for mode in ['train', 'val']:\n",
    "            if mode == 'train':\n",
    "                model.train()\n",
    "                data_loader = train_dataloader\n",
    "            else:\n",
    "                model.eval() \n",
    "                data_loader = val_dataloader\n",
    "          \n",
    "            epoch_loss = 0\n",
    "            epoch_iou = 0\n",
    "           \n",
    "            start_time = time.time()\n",
    "            for idx, batch in enumerate(tqdm(data_loader)):\n",
    "                imgs, masks, names = batch\n",
    "                images = imgs.to(device, dtype=torch.float)\n",
    "                masks = masks.to(device, dtype=torch.float)\n",
    "            \n",
    "                if mode == 'train':\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    masks_pred = model(images)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        masks_pred = model(images)\n",
    "\n",
    "                loss = criterion(masks_pred.squeeze(1), masks)\n",
    "                loss += dice_loss(masks_pred.squeeze(1), masks)\n",
    "                \n",
    "                iou = jaccard(masks_pred.squeeze(1).cpu(), masks.cpu())\n",
    "\n",
    "                if idx == len(data_loader) - 2 and epoch%args.checkpoint_interval==0: # Save images on the batch before the last one so that there are at least 4 images in the batch\n",
    "                    img_batch = torch.cat((images[:args.imgs_to_save,...], masks[:args.imgs_to_save,...].unsqueeze(1).expand(-1, 3, -1, -1), masks_pred[:args.imgs_to_save,...].expand(-1, 3, -1, -1)), 2)\n",
    "                    tensorboard_writer.add_images(f'Input images, ground truths and predicted masks/{mode}', img_batch[:args.imgs_to_save,...], epoch)\n",
    "                    name_str =\"\".join([f\"  \\n{names[i]}\" for i in range(args.imgs_to_save)])\n",
    "                    tensorboard_writer.add_text(f\"Metadata/{mode}\", f'loss: {loss}  \\niou: {iou}' + name_str, epoch)\n",
    "                \n",
    "                tensorboard_writer.add_scalar(f\"Batch_loss/{mode}\", loss, epoch * len(data_loader) + idx)\n",
    "                tensorboard_writer.add_scalar(f\"Batch_IOU/{mode}\", iou, epoch * len(data_loader) + idx)\n",
    "                \n",
    "                if mode == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_iou += iou.item()\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "            epoch_iou = epoch_iou / len(data_loader)\n",
    "            \n",
    "            tensorboard_writer.add_scalar(f\"Epoch_loss/{mode}\", epoch_loss , epoch)\n",
    "            tensorboard_writer.add_scalar(f\"Epoch_IOU/{mode}\", epoch_iou, epoch)\n",
    "\n",
    "            print(\n",
    "                'Mode: {}, Epoch: {}, Time: {:.6f} s, Loss: {:.6f}, IoU: {:.6f}'.format(\n",
    "                    mode, epoch, end_time-start_time, epoch_loss, epoch_iou\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if mode=='val' and epoch_iou > best_iou:\n",
    "                best_iou = epoch_iou\n",
    "                save_model(checkpoint_dir, model, optimizer, epoch, f\"image_model_best_iou-{round(epoch_iou, 3)}\")\n",
    "\n",
    "            if mode == 'val' and epoch%args.checkpoint_interval==0:\n",
    "                save_model(checkpoint_dir, model, optimizer, epoch, f\"image_model_epoch-{epoch}_iou-{round(epoch_iou, 3)}\")\n",
    "\n",
    "            if mode == 'val' and args.run_inference is True and epoch%args.inference_interval==0:\n",
    "                output_dir = f\"{checkpoint_dir}/inference_result_epoch-{epoch}_iou-{epoch_iou}\"\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "\n",
    "                input_dir = args.test_data_path # A folder that contains PDFs and JPGs\n",
    "                for filename in os.scandir(input_dir):\n",
    "                    if filename.is_file() and '.pdf' in filename.name:\n",
    "                        images = convert_from_path(filename.path)\n",
    "                        for idx, img in enumerate(images):\n",
    "                            output_path = f\"{output_dir}/{filename.name[:-4]}_{idx}\"\n",
    "                            run_prediction(img, model, device, args.input_shape[0], output_path)\n",
    "                    elif filename.is_file() and ('.jpg' in filename.name or '.jpeg' in filename.name):\n",
    "                        img = cv2.imread(filename.path)\n",
    "                        output_path = f\"{output_dir}/{filename.name[:-4]}\"\n",
    "                        run_prediction(img, model, device, args.input_shape[0], output_path)\n",
    "                print(f\"Inference completed\")\n",
    "            \n",
    "            if device.type != 'cpu': # If the device is a GPU, empty the cache\n",
    "                getattr(torch, device.type).empty_cache()\n",
    "                \n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Training is logged in results/Unet3+_TEST_RUN_2024-01-04_20-18-58 \n",
      "\n",
      "📁 Train dataset len: 70, train loader batch count: 18\n",
      "📂 Val dataset len: 20, val loader batch count: 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "project_dir = Path(args.project_dir)\n",
    "checkpoint_dir = Path(project_dir/f\"{args.run_name}_{timestamp}\")\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"\\n💾 Training is logged in {checkpoint_dir} \\n\")\n",
    "\n",
    "train_transform = A.Compose([\n",
    "            A.RandomResizedCrop(height=args.input_shape[0], width=args.input_shape[0], scale=(0.20,1.0), ratio=(0.8, 1.2), p=1.0),\n",
    "            A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.25),\n",
    "            A.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=0.05, p=0.75),\n",
    "            A.RandomGamma(p=0.50),\n",
    "            A.OneOf([\n",
    "                A.GaussNoise(var_limit=(10, 70), p=0.2), \n",
    "                A.ImageCompression(quality_lower=97, p=0.2),\n",
    "                A.ISONoise(intensity=(0.1, 0.5), p=0.2),\n",
    "                A.MultiplicativeNoise(multiplier=(0.8, 1.2), p=0.2),\n",
    "                A.AdvancedBlur(blur_limit=(3, 5), p=0.2),\n",
    "                A.Blur(blur_limit=(3, 5), p=0.2)],\n",
    "                    p=0.5),\n",
    "            ToTensorV2()])\n",
    "    \n",
    "val_transform = A.Compose([\n",
    "        A.RandomResizedCrop(height=args.input_shape[0], width=args.input_shape[0], scale=(0.20,1.0), ratio=(0.8, 1.2), p=1.0),\n",
    "        ToTensorV2()])\n",
    "\n",
    "train_items, val_items = dataset_splitter(args.data_paths, args.train_split_size, args.percentage_of_data_to_use, seed=0)\n",
    "\n",
    "train_dataset = PaperworkDataset(train_items, args.input_shape, train_transform, args.input_shape[0])\n",
    "val_dataset = PaperworkDataset(val_items, args.input_shape, val_transform, args.input_shape[0])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=False,\n",
    "                                            num_workers=args.num_workers,\n",
    "                                            prefetch_factor=args.batch_prefetch_factor)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=False,\n",
    "                                            num_workers=args.num_workers,\n",
    "                                            prefetch_factor=args.batch_prefetch_factor)\n",
    "\n",
    "print(f\"📁 Train dataset len: {len(train_dataset)}, train loader batch count: {len(train_loader)}\")\n",
    "print(f\"📂 Val dataset len: {len(val_dataset)}, val loader batch count: {len(val_loader)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Using computational power: cuda \n",
      "\n",
      "📂 Loaded checkpoint './results/Unet3+_restart_2024-01-02_16-15-36/image_model_best_iou-0.761.pth' (epoch 105) \n",
      "\n",
      "📐 Model initialized \n",
      "🧮 All parameter count: 176557, \n",
      "📏 Trainable parameter count: 176557 \n",
      "\n",
      "⌛ Model training will start from epoch no 105 and run till epoch no 115  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=checkpoint_dir)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"🤖 Using computational power: {device} \\n\")\n",
    "\n",
    "model = Unet3Plus()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.RAdam(params=model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "start_epoch = 0\n",
    "epochs=args.epoch_count\n",
    "if len(args.checkpoint_path):\n",
    "    model, optimizer, start_epoch = load_checkpoint(model, optimizer, args.checkpoint_path)\n",
    "    epochs += start_epoch\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"📐 Model initialized \\n\"\n",
    "        f\"🧮 All parameter count: {total_params}, \\n\"\n",
    "        f\"📏 Trainable parameter count: {trainable_params} \\n\")\n",
    "\n",
    "print(f\"⌛ Model training will start from epoch no {start_epoch} and run till epoch no {epochs}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(model=model, \n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device, \n",
    "        start_epoch = start_epoch,\n",
    "        epochs=epochs, \n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        tensorboard_writer = writer)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
